{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "685f4212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts inscript.exe and inscriptis-api.exe are installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script ir_datasets.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts accelerate-config.exe, accelerate-estimate-memory.exe, accelerate-launch.exe, accelerate-merge-weights.exe and accelerate.exe are installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script transformers-cli.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script datasets-cli.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.41 requires requests_mock, which is not installed.\n",
      "conda-repo-cli 1.0.41 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires nbformat==5.4.0, but you have nbformat 5.7.0 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires requests==2.28.1, but you have requests 2.32.3 which is incompatible.\n",
      "s3fs 2023.3.0 requires fsspec==2023.3.0, but you have fsspec 2024.3.1 which is incompatible.\n",
      "  WARNING: The script uvicorn.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script typer.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script httpx.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script fastapi.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts gradio.exe and upload_theme.exe are installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-cloud-auth 0.1.4 requires pydantic<2.0, but you have pydantic 2.10.3 which is incompatible.\n",
      "  WARNING: The script filetype.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tqdm.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script distro.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script nltk.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script openai.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script llamaindex-legacy-cli.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script llama-parse.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script llamaindex-cli.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script llamaindex-cli.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "conda-repo-cli 1.0.41 requires requests_mock, which is not installed.\n",
      "conda-repo-cli 1.0.41 requires clyent==1.2.1, but you have clyent 1.2.2 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires nbformat==5.4.0, but you have nbformat 5.7.0 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires PyYAML==6.0, but you have pyyaml 6.0.2 which is incompatible.\n",
      "conda-repo-cli 1.0.41 requires requests==2.28.1, but you have requests 2.32.3 which is incompatible.\n",
      "python-lsp-black 1.2.1 requires black>=22.3.0, but you have black 0.0 which is incompatible.\n",
      "s3fs 2023.3.0 requires fsspec==2023.3.0, but you have fsspec 2024.3.1 which is incompatible.\n",
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "numba 0.57.0 requires numpy<1.25,>=1.21, but you have numpy 2.2.0 which is incompatible.\n",
      "scipy 1.10.1 requires numpy<1.27.0,>=1.19.5, but you have numpy 2.2.0 which is incompatible.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gradio 5.9.0 requires huggingface-hub>=0.25.1, but you have huggingface-hub 0.23.5 which is incompatible.\n",
      "peft 0.14.0 requires huggingface-hub>=0.25.0, but you have huggingface-hub 0.23.5 which is incompatible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "gradio 5.9.0 requires huggingface-hub>=0.25.1, but you have huggingface-hub 0.23.5 which is incompatible.\n",
      "peft 0.14.0 requires huggingface-hub>=0.25.0, but you have huggingface-hub 0.23.5 which is incompatible.\n",
      "numba 0.57.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.\n",
      "  WARNING: The script huggingface-cli.exe is installed in 'C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-llms-huggingface 0.4.1 requires huggingface-hub<0.24.0,>=0.23.0, but you have huggingface-hub 0.26.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -U FlagEmbedding -q\n",
    "!pip install gradio --q\n",
    "!pip install -q llama-index\n",
    "!pip install -q llama-core\n",
    "!pip install -q llama-index-llms-huggingface\n",
    "!pip install -q llama-index-embeddings-huggingface\n",
    "!pip install -q llama-index-embeddings-huggingface-api\n",
    "!pip install groq -q\n",
    "!pip install rank_bm25 -q\n",
    "!pip install --upgrade huggingface_hub -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c2de79",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c188dffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Legion\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import os\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "from FlagEmbedding import FlagReranker\n",
    "from groq import Groq\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc6d031",
   "metadata": {},
   "source": [
    "## Loading data, cleaning, chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d1be664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_without_header(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file, removing headers.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    pdf_path: str\n",
    "        Path to the PDF file.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    text: str\n",
    "        The extracted text from the PDF.\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page_number, page in enumerate(pdf.pages, start=1):\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                # Remove repetitive headers or unwanted page numbers\n",
    "                page_text = page_text.split(\"\\n\", 1)[-1]\n",
    "            text += page_text + \"\\n\" if page_text else \"\\n\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7e5a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_file_path = \"Harry Potter and the Sorcerers Stone.pdf\"\n",
    "pdf_text = extract_text_without_header(pdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6223ca8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_chapters(text):\n",
    "    \"\"\"\n",
    "    Split the text into chapters using a delimiter ('CHAPTER', for example).\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    text: str\n",
    "        Full text extracted from the PDF.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    chapters: list\n",
    "        List of chapters as individual strings.\n",
    "    \"\"\"\n",
    "    chapters = re.split(r'\\bCHAPTER\\s+\\d+', text, flags=re.IGNORECASE)\n",
    "    chapters = [chapter.strip() for chapter in chapters if chapter.strip()]  # Clean empty entries\n",
    "    return chapters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71a6e842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chapters: 1\n",
      "Sample chapter content:\n",
      "CHAPTER ONE\n",
      "THE BOY WHO LIVED\n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
      "that they were perfectly normal, thank you very much. They were the last\n",
      "people you'd expect to be involved in anything strange or mysterious,\n",
      "because they just didn't hold with such nonsense.\n",
      "Mr. Dursley was the director of a firm called Grunnings, which made\n",
      "drills. He was a big, beefy man with hardly any neck, although he did\n",
      "have a very large mustache. Mrs. Dursley was thin and blonde and had\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chapters = split_to_chapters(pdf_text)\n",
    "print(f\"Number of chapters: {len(chapters)}\")\n",
    "print(f\"Sample chapter content:\\n{chapters[0][:500]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7b22bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_chapters(chapters):\n",
    "    \"\"\"\n",
    "    Clean chapter text by removing artifacts such as page numbers or line breaks.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    chapters: list\n",
    "        List of chapter strings.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    cleaned_chapters: list\n",
    "        List of cleaned chapter strings.\n",
    "    \"\"\"\n",
    "    cleaned_chapters = []\n",
    "    for chapter in chapters:\n",
    "        # Remove unwanted line breaks and normalize spacing\n",
    "        cleaned_chapter = re.sub(r'\\n+', ' ', chapter)\n",
    "        cleaned_chapter = re.sub(r'\\s{2,}', ' ', cleaned_chapter)\n",
    "        cleaned_chapters.append(cleaned_chapter.strip())\n",
    "    return cleaned_chapters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db04e0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER ONE THE BOY WHO LIVED Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense. Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had \n"
     ]
    }
   ],
   "source": [
    "cleaned_chapters = clean_chapters(chapters)\n",
    "print(cleaned_chapters[0][:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "575e718a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_to_sections(chapters, max_words=500):\n",
    "    \"\"\"\n",
    "    Split chapters into smaller sections of a defined word limit.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    chapters: list\n",
    "        List of chapter strings.\n",
    "    max_words: int\n",
    "        Maximum number of words per section.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    sections: list\n",
    "        List of section dictionaries with metadata.\n",
    "    \"\"\"\n",
    "    sections = []\n",
    "    for chapter_number, chapter in enumerate(chapters, start=1):\n",
    "        words = chapter.split()\n",
    "        for i in range(0, len(words), max_words):\n",
    "            section_text = \" \".join(words[i:i + max_words])\n",
    "            sections.append({\n",
    "                \"chapter_number\": chapter_number,\n",
    "                \"section_number\": i // max_words + 1,\n",
    "                \"text\": section_text\n",
    "            })\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a091a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sections: 153\n",
      "Sample section: {'chapter_number': 1, 'section_number': 1, 'text': 'CHAPTER ONE THE BOY WHO LIVED Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you\\'d expect to be involved in anything strange or mysterious, because they just didn\\'t hold with such nonsense. Mr. Dursley was the director of a firm called Grunnings, which made drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors. The Dursleys had a small son called Dudley and in their opinion there was no finer boy anywhere. The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it. They didn\\'t think they could bear it if anyone found out about the Potters. Mrs. Potter was Mrs. Dursley\\'s sister, but they hadn\\'t met for several years; in fact, Mrs. Dursley pretended she didn\\'t have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be. The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street. The Dursleys knew that the Potters had a small son, too, but they had never even seen him. This boy was another good reason for keeping the Potters away; they didn\\'t want Dudley mixing with a child like that. When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story starts, there was nothing about the cloudy sky outside to suggest that strange and mysterious things would soon be happening all over the country. Mr. Dursley hummed as he picked out his most boring tie for work, and Mrs. Dursley gossiped away happily as she wrestled a screaming Dudley into his high chair. None of them noticed a large, tawny owl flutter past the window. At half past eight, Mr. Dursley picked up his briefcase, pecked Mrs. Dursley on the cheek, and tried to kiss Dudley good-bye but missed, 1 walls. \"Little tyke,\" chortled Mr. Dursley as he left the house. He got into his car and backed out of number four\\'s drive. It was on the corner of the street that he noticed the first sign of something peculiar -- a cat reading a map. For a second, Mr. Dursley didn\\'t realize what he had seen -- then he jerked his head around to look again. There was a tabby cat standing on the corner of Privet Drive, but there wasn\\'t a map in sight. What could he have been thinking of? It must have been a trick of the light. Mr. Dursley blinked and stared at the cat. It stared back. As Mr. Dursley drove around the corner and up the road, he watched the cat in'}\n"
     ]
    }
   ],
   "source": [
    "sections = split_to_sections(cleaned_chapters)\n",
    "print(f\"Number of sections: {len(sections)}\")\n",
    "print(f\"Sample section: {sections[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d017687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_txt(content, filename, directory):\n",
    "    with open(os.path.join(directory, f\"{filename}.txt\"), 'w', encoding='utf-8') as file:\n",
    "        file.write(content)\n",
    "        \n",
    "def save_sections_as_files(sections, output_dir, file_format='txt'):\n",
    "    \"\"\"\n",
    "    Save sections into individual files.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    sections: list\n",
    "        List of section dictionaries.\n",
    "    output_dir: str\n",
    "        Directory where files will be saved.\n",
    "    file_format: str\n",
    "        Desired file format (e.g., 'txt').\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for section in sections:\n",
    "        filename = f\"Chapter_{section['chapter_number']}_Section_{section['section_number']}\"\n",
    "        if file_format.lower() == 'txt':\n",
    "            save_as_txt(section['text'], filename, output_dir)\n",
    "    print(f\"Sections saved in: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3014cfb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sections saved in: sections\n"
     ]
    }
   ],
   "source": [
    "save_sections_as_files(sections, \"sections\", file_format='txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1404173",
   "metadata": {},
   "source": [
    "## Semanthic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b3cd8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index_with_metadata(directory_path):\n",
    "    \"\"\"\n",
    "    Create a semantic search index from text files, with enhanced metadata support.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    directory_path: str\n",
    "        Path to the directory containing text files.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    index: VectorStoreIndex\n",
    "        The created semantic index.\n",
    "    metadata_map: dict\n",
    "        Mapping of document IDs to their metadata (chapter, section).\n",
    "    \"\"\"\n",
    "    embed_model = HuggingFaceEmbedding(model_name=\"intfloat/multilingual-e5-large\")\n",
    "\n",
    "    reader = SimpleDirectoryReader(directory_path)\n",
    "    documents = reader.load_data() \n",
    "\n",
    "    # Initialize metadata map\n",
    "    metadata_map = {}\n",
    "    for idx, doc in enumerate(documents):\n",
    "        file_name = doc.metadata.get(\"file_name\", f\"Unknown_{idx}\")  # Default name if missing\n",
    "        chapter, section = extract_chapter_section(file_name)\n",
    "\n",
    "        # Add a unique document ID\n",
    "        document_id = f\"doc_{idx}\"\n",
    "        doc.metadata.update({\n",
    "            \"document_id\": document_id,\n",
    "            \"chapter\": chapter,\n",
    "            \"section\": section,\n",
    "        })\n",
    "\n",
    "        metadata_map[document_id] = doc.metadata\n",
    "\n",
    "    # Create and return the semantic index\n",
    "    index = VectorStoreIndex.from_documents(documents, embed_model=embed_model)\n",
    "    return index, metadata_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a4ceba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_chapter_section(file_name):\n",
    "    \"\"\"\n",
    "    Extract chapter and section numbers from the file name.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    file_name: str\n",
    "        File name (e.g., \"Chapter_1_Section_3.txt\").\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    chapter: int\n",
    "        The chapter number.\n",
    "    section: int\n",
    "        The section number within the chapter.\n",
    "    \"\"\"\n",
    "    match = re.match(r\"Chapter_(\\d+)_Section_(\\d+).txt\", file_name)\n",
    "    if match:\n",
    "        chapter = int(match.group(1))\n",
    "        section = int(match.group(2))\n",
    "        return chapter, section\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49bc6ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_semantic_search(query, index, metadata_map, top_k=5, score_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Perform semantic search on the index.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    query: str\n",
    "        The user query for searching relevant sections.\n",
    "    index: VectorStoreIndex\n",
    "        The semantic search index.\n",
    "    metadata_map: dict\n",
    "        Mapping of document IDs to metadata.\n",
    "    top_k: int\n",
    "        Number of top results to retrieve.\n",
    "    score_threshold: float\n",
    "        Minimum similarity score to include a result.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    results: list\n",
    "        List of dictionaries containing matched sections and metadata.\n",
    "    \"\"\"\n",
    "    retriever = index.as_retriever(similarity_top_k=top_k)\n",
    "    response = retriever.retrieve(query)\n",
    "\n",
    "    results = []\n",
    "    for node in response:\n",
    "        # Fetch metadata for the document\n",
    "        doc_id = node.node.metadata[\"document_id\"]\n",
    "        metadata = metadata_map.get(doc_id, {})\n",
    "        score = node.score\n",
    "\n",
    "        if score >= score_threshold:\n",
    "            results.append({\n",
    "                \"text\": node.node.text,\n",
    "                \"score\": score,\n",
    "                \"chapter\": metadata.get(\"chapter\"),\n",
    "                \"section\": metadata.get(\"section\"),\n",
    "            })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0388a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_search_results(results):\n",
    "    \"\"\"\n",
    "    Display search results in a user-friendly format.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    results: list\n",
    "        List of dictionaries containing search results and metadata.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"No matching sections found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Top {len(results)} Results:\")\n",
    "    for idx, result in enumerate(results, start=1):\n",
    "        print(f\"\\nResult {idx}:\")\n",
    "        print(f\"Chapter: {result['chapter']}, Section: {result['section']}\")\n",
    "        print(f\"Score: {result['score']:.2f}\")\n",
    "        print(f\"Text: {result['text'][:500]}...\")  # Show snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5da14c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_path = \"sections\"\n",
    "index, metadata_map = create_index_with_metadata(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "baac33a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Results:\n",
      "\n",
      "Result 1:\n",
      "Chapter: 1, Section: 109\n",
      "Score: 0.82\n",
      "Text: Hermione ignored him. \"Nicolas Flamel,\" she whispered dramatically, \"is the only known maker of the Sorcerer's Stone!\" This didn't have quite the effect she'd expected. \"The what?\" said Harry and Ron. \"Oh, honestly, don't you two read? Look -- read that, there.\" She pushed the book toward them, and Harry and Ron read: The ancient study of alchemy is concerned with making the Sorcerer's Stone, a 175 any metal into pure gold. It also produces the Elixir of Life, which will make the drinker immorta...\n",
      "\n",
      "Result 2:\n",
      "Chapter: 1, Section: 69\n",
      "Score: 0.79\n",
      "Text: high into the air as it would go without her leaving her seat, but Harry didn't have the faintest idea what a bezoar was. He tried not to look at Malfoy, Crabbe, and Goyle, who were shaking with laughter. \"I don't know, sit.\" \"Thought you wouldn't open a book before coming, 109 cold eyes. He had looked through his books at the Dursleys', but did Snape expect him to remember everything in One Thousand Magical Herbs and Fungi? Snape was still ignoring Hermione's quivering hand. \"What is the differ...\n",
      "\n",
      "Result 3:\n",
      "Chapter: 1, Section: 144\n",
      "Score: 0.78\n",
      "Text: mirror? Should I break it?\" Harry's mind was racing. What I want more than anything else in the world at the moment, he thought, is to find the Stone before Quirrell does. So if I look in the mirror, I should see myseff finding it -- which means I'll see where it's hidden! But how can I look without Quirrell realizing what I'm up 234 He tried to edge to the left, to get in front of the glass without Quirrell noticing, but the ropes around his ankles were too tight: he tripped and fell over. Quir...\n"
     ]
    }
   ],
   "source": [
    "query = \"What is Sorcerer's Stone?\"\n",
    "results = perform_semantic_search(query, index, metadata_map, top_k=3, score_threshold=0.3)\n",
    "\n",
    "# Display results\n",
    "display_search_results(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb6917",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "89b40e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus(sections):\n",
    "    \"\"\"\n",
    "    Preprocess sections into a tokenized corpus and metadata.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    sections: list\n",
    "        List of dictionaries containing text and metadata.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    corpus: list\n",
    "        Tokenized list of words for each section.\n",
    "    metadata: list\n",
    "        Metadata for each section.\n",
    "    \"\"\"\n",
    "    corpus = []\n",
    "    metadata = []\n",
    "    \n",
    "    for section in sections:\n",
    "        text = section[\"text\"].lower()  # Lowercase for consistency\n",
    "        tokens = word_tokenize(text)   # Tokenize into words\n",
    "        corpus.append(tokens)\n",
    "        metadata.append({\n",
    "            \"chapter_number\": section[\"chapter_number\"],  \n",
    "            \"section_number\": section[\"section_number\"], \n",
    "            \"text\": section[\"text\"]\n",
    "        })\n",
    "    \n",
    "    return corpus, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1a044ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bm25_search(query, corpus, metadata, top_n=3):\n",
    "    \"\"\"\n",
    "    Perform BM25 search on the dataset.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    query: str\n",
    "        The user query.\n",
    "    corpus: list\n",
    "        The tokenized corpus.\n",
    "    metadata: list\n",
    "        Metadata corresponding to each section.\n",
    "    top_n: int\n",
    "        Number of top results to return.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    results: list\n",
    "        List of top matching documents with scores and metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    bm25 = BM25Okapi(corpus)\n",
    "\n",
    "    # Tokenize the query\n",
    "    query_tokens = word_tokenize(query.lower())\n",
    "\n",
    "    # Compute BM25 scores for all documents\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "\n",
    "    # Get the top N results\n",
    "    top_indices = np.argsort(scores)[-top_n:][::-1]\n",
    "\n",
    "    results = []\n",
    "    for idx in top_indices:\n",
    "        result = {\n",
    "            \"chapter_number\": metadata[idx][\"chapter_number\"],  # Updated key\n",
    "            \"section_number\": metadata[idx][\"section_number\"],  # Updated key\n",
    "            \"text\": metadata[idx][\"text\"],\n",
    "            \"score\": scores[idx]\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54e26221",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results_bm25(results):\n",
    "    \"\"\"\n",
    "    Display BM25 search results in a user-friendly format.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    results: list\n",
    "        List of dictionaries containing search results.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    if not results:\n",
    "        print(\"No matching sections found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Top {len(results)} Results:\")\n",
    "    for idx, result in enumerate(results, start=1):\n",
    "        print(f\"\\nResult {idx}:\")\n",
    "        print(f\"Chapter: {result['chapter_number']}, Section: {result['section_number']}\")\n",
    "        print(f\"Score: {result['score']:.2f}\")\n",
    "        print(f\"Text: {result['text'][:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95c3ba3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Results:\n",
      "\n",
      "Result 1:\n",
      "Chapter: 1, Section: 109\n",
      "Score: 11.61\n",
      "Text: Hermione ignored him. \"Nicolas Flamel,\" she whispered dramatically, \"is the only known maker of the Sorcerer's Stone!\" This didn't have quite the effect she'd expected. \"The what?\" said Harry and Ron. \"Oh, honestly, don't you two read? Look -- read that, there.\" She pushed the book toward them, and Harry and Ron read: The ancient study of alchemy is concerned with making the Sorcerer's Stone, a 175 any metal into pure gold. It also produces the Elixir of Life, which will make the drinker immorta...\n",
      "\n",
      "Result 2:\n",
      "Chapter: 1, Section: 144\n",
      "Score: 11.59\n",
      "Text: mirror? Should I break it?\" Harry's mind was racing. What I want more than anything else in the world at the moment, he thought, is to find the Stone before Quirrell does. So if I look in the mirror, I should see myseff finding it -- which means I'll see where it's hidden! But how can I look without Quirrell realizing what I'm up 234 He tried to edge to the left, to get in front of the glass without Quirrell noticing, but the ropes around his ankles were too tight: he tripped and fell over. Quir...\n",
      "\n",
      "Result 3:\n",
      "Chapter: 1, Section: 149\n",
      "Score: 11.49\n",
      "Text: going to -- Dumbledore was so worried --\" \"The whole school's talking about it,\" said Ron. \"What really happened?\" It was one of those rare occasions when the true story is even more strange and exciting than the wild rumors. Harry told them everything: Quirrell; the mirror; the Stone; and Voldemort. Ron and Hermione were a very good audience; they gasped in all the right places, and when Harry told them what was under Quirrell's turban, Hermione screamed out loud. \"So the Stone's gone?\" said Ro...\n"
     ]
    }
   ],
   "source": [
    "corpus, metadata = preprocess_corpus(sections)\n",
    "\n",
    "query = \"What is a Philosopher's Stone?\"\n",
    "results = bm25_search(query, corpus, metadata, top_n=3)\n",
    "\n",
    "display_results_bm25(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ec3d62",
   "metadata": {},
   "source": [
    "## Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c4ad48c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32cc023137c465ca331fae4ca23e77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Legion\\.cache\\huggingface\\hub\\models--BAAI--bge-reranker-v2-m3. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd427c2fd4a4641877d334b3294b339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc06f85e0f104583b9570de09f3562c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6a7865ff11499dbd2c0baae7d92558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e7c119fbc240aa9b3c5b8277e90e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/795 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfde36208724cfbaf5b270808150f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reranker = FlagReranker('BAAI/bge-reranker-v2-m3', use_fp16=True)\n",
    "\n",
    "def use_reranker(query, documents, top_k=3):\n",
    "    \"\"\"\n",
    "    Use a reranker to refine search results for better relevance.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    query: str\n",
    "        The user query for reranking.\n",
    "    documents: list\n",
    "        List of dictionaries containing document metadata and text.\n",
    "    top_k: int\n",
    "        Number of top results to return after reranking.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    top_docs: list\n",
    "        Reranked list of top matching documents with scores and metadata.\n",
    "    \"\"\"\n",
    "\n",
    "    pairs = [[query, doc[\"text\"]] for doc in documents]\n",
    "    \n",
    "    scores = reranker.compute_score(pairs, normalize=True)\n",
    "    top_indices = np.argsort(scores)[-top_k:][::-1]\n",
    "    \n",
    "    # Retrieve the top documents along with their scores\n",
    "    top_docs = [\n",
    "        {\n",
    "            \"chapter_number\": documents[i].get(\"chapter_number\"),\n",
    "            \"section_number\": documents[i].get(\"section_number\"),\n",
    "            \"text\": documents[i][\"text\"],\n",
    "            \"bm25_score\": documents[i].get(\"score\"), \n",
    "            \"reranker_score\": scores[i]\n",
    "        }\n",
    "        for i in top_indices\n",
    "    ]\n",
    "    \n",
    "    return top_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42d5baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_reranked_results(results):\n",
    "    \"\"\"\n",
    "    Display reranked search results in a user-friendly format.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    results: list\n",
    "        List of dictionaries containing reranked results and metadata.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    if not results:\n",
    "        print(\"No matching sections found.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Top {len(results)} Results (Reranked):\")\n",
    "    for idx, result in enumerate(results, start=1):\n",
    "        print(f\"\\nResult {idx}:\")\n",
    "        print(f\"Chapter: {result['chapter_number']}, Section: {result['section_number']}\")\n",
    "        print(f\"BM25 Score: {result['bm25_score']:.2f}\")\n",
    "        print(f\"Reranker Score: {result['reranker_score']:.2f}\")\n",
    "        print(f\"Text: {result['text'][:500]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1915411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a XLMRobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the Sorcerer's Stone?\"\n",
    "\n",
    "bm25_results = bm25_search(query, corpus, metadata, top_n=5)\n",
    "\n",
    "reranked_results = use_reranker(query, bm25_results, top_k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a2ef37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Results (Reranked):\n",
      "\n",
      "Result 1:\n",
      "Chapter: 1, Section: 109\n",
      "BM25 Score: 17.48\n",
      "Reranker Score: 0.79\n",
      "Text: Hermione ignored him. \"Nicolas Flamel,\" she whispered dramatically, \"is the only known maker of the Sorcerer's Stone!\" This didn't have quite the effect she'd expected. \"The what?\" said Harry and Ron. \"Oh, honestly, don't you two read? Look -- read that, there.\" She pushed the book toward them, and Harry and Ron read: The ancient study of alchemy is concerned with making the Sorcerer's Stone, a 175 any metal into pure gold. It also produces the Elixir of Life, which will make the drinker immorta...\n",
      "\n",
      "Result 2:\n",
      "Chapter: 1, Section: 112\n",
      "BM25 Score: 14.63\n",
      "Reranker Score: 0.34\n",
      "Text: on? Harry jumped back on his Nimbus Two Thousand and took off. Gliding silently over the castle he saw Snape enter the forest at a run. He followed. The trees were so thick he couldn't see where Snape had gone. He flew in circles, lower and lower, brushing the top branches of trees until he heard voices. He glided toward them and landed noiselessly in a towering beech tree. He climbed carefully along one of the branches, holding tight to his broomstick, trying to see through the leaves. Below, i...\n",
      "\n",
      "Result 3:\n",
      "Chapter: 1, Section: 113\n",
      "BM25 Score: 15.24\n",
      "Reranker Score: 0.20\n",
      "Text: THE NORWEGIAN RIDGEBACK Quirrell, however, must have been braver than they'd thought. In the weeks that followed he did seem to be getting paler and thinner, but it didn't look as though he'd cracked yet. Every time they passed the third-floor corridor, Harry, Ron, and Hermione would press their ears to the door to check that Fluffy was still growling inside. Snape was sweeping about in his usual bad temper, which surely meant that the Stone was still safe. Whenever Harry passed Quirrell these d...\n"
     ]
    }
   ],
   "source": [
    "display_reranked_results(reranked_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d91393",
   "metadata": {},
   "source": [
    "## LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aaaa4814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(docs):\n",
    "    \"\"\"\n",
    "    Create a textual context from the provided documents.\n",
    "\n",
    "    Args:\n",
    "    ----------\n",
    "    docs: list\n",
    "        List of dictionaries containing document metadata and text.\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    context: str\n",
    "        A concatenated string of documents with their metadata.\n",
    "    \"\"\"\n",
    "    context = ''\n",
    "    for i, doc_info in enumerate(docs, start=1):\n",
    "        context += f\"Document {i} (Chapter {doc_info.get('chapter_number')}, Section {doc_info.get('section_number')}):\\n\"\n",
    "        context += doc_info['text'] + \"\\n\\n\"\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6cef806",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_rag(query, index, corpus, metadata, method='semantic', top_n=3, rerank=False):\n",
    "    \"\"\"\n",
    "    Perform Retrieval-Augmented Generation by searching for relevant documents.\n",
    "    \"\"\"\n",
    "    if method == 'bm25':\n",
    "        print(\"Performing BM25 Search...\")\n",
    "        top_docs = bm25_search(query, corpus, metadata, top_n=top_n)\n",
    "    elif method == 'semantic':\n",
    "        print(\"Performing Semantic Search...\")\n",
    "        top_docs = semantic_search(query, index, top_n=top_n)\n",
    "    else:\n",
    "        print(\"No search method specified.\")\n",
    "        return []\n",
    "\n",
    "    if rerank:\n",
    "        print(\"Performing Reranking...\")\n",
    "        top_docs = use_reranker(query, top_docs, top_k=top_n)\n",
    "\n",
    "    return top_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f7d3972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_llm(query, use_context, groq_key_input, top_docs=None, system_prompt=\"\", temperature=0.7):\n",
    "    \"\"\"\n",
    "    Perform LLM-based question answering with optional context.\n",
    "    \"\"\"\n",
    "\n",
    "    if use_context == 1 and top_docs:\n",
    "        context = create_context(top_docs)\n",
    "        llm_query = (\n",
    "            system_prompt\n",
    "            + \"Question: \" + query + \"\\n\"\n",
    "            + \"Context: \" + context + \"\\n\"\n",
    "            + \"Answer: \"\n",
    "        )\n",
    "    else:\n",
    "        llm_query = (\n",
    "            system_prompt\n",
    "            + \"Question: \" + query + \"\\n\"\n",
    "            + \"Context: []\\n\"\n",
    "            + \"Answer: \"\n",
    "        )\n",
    "\n",
    "\n",
    "    client = Groq(api_key=api_key)\n",
    "\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": llm_query,\n",
    "        }],\n",
    "        model=\"gemma-7b-it\",\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    return chat_completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "66a0af15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing BM25 Search...\n",
      "Performing Reranking...\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the Sorcerer's Stone?\"\n",
    "system_prompt = \"You are a knowledgeable assistant summarizing text from Harry Potter.\"\n",
    "top_docs = perform_rag(query, index, corpus, metadata, method='bm25', top_n=5, rerank=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d16f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Key for LLM Service\n",
    "api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "018cda59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      " The Sorcerer's Stone is a mythical potion that can turn base metals into gold and grant immortality. It is said to be the most valuable and powerful object in the wizarding world.\n"
     ]
    }
   ],
   "source": [
    "# Generate response using the top documents as context\n",
    "response = perform_llm(\n",
    "    query=query,\n",
    "    use_context=1,\n",
    "    api_key=api_key,\n",
    "    top_docs=top_docs,\n",
    "    system_prompt=system_prompt,\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"LLM Response:\\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eb5106",
   "metadata": {},
   "source": [
    "## Web Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "abde7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_interface():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"## Harry Potter Book Search and LLM Query System\")\n",
    "        gr.Markdown(\"This service allows you to perform semantic search, BM25 search, and reranking of documents with an option to use context for querying the LLM. If no search is specified, the LLM will use its own knowledge to answer.\")\n",
    "        \n",
    "        BOOK_URL = \"https://docenti.unimc.it/antonella.pascali/teaching/2018/19055/files/ultima-lezione/harry-potter-and-the-philosophers-stone\"  # Replace with actual link to the book\n",
    "        gr.Markdown(f'<p style=\"font-size: 18px;\">Read the book here: <a href=\"{BOOK_URL}\" style=\"color: orange; text-decoration: underline;\">Harry Potter Book</a></p>')\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                query_input = gr.Textbox(label=\"Your Query\", placeholder=\"For example, What is Harry Potter's first spell?\")\n",
    "                \n",
    "                method_input = gr.Radio(\n",
    "                    choices=[\"semantic\", \"bm25\", \"no search\"], label=\"Search Method\", value=\"semantic\"\n",
    "                )\n",
    "\n",
    "                groq_key_input = gr.Textbox(label=\"Groq API Key\", type=\"password\")\n",
    "\n",
    "                rerank_input = gr.Checkbox(label=\"Use Reranker\", value=False)\n",
    "\n",
    "                temperature_input = gr.Slider(minimum=0, maximum=1, step=0.1, label=\"Temperature\", value=0.5)\n",
    "                use_context = gr.Checkbox(label=\"Use Context for Query\", value=True)\n",
    "\n",
    "            with gr.Column():\n",
    "                results_output = gr.Textbox(label=\"Search Results and LLM Answer\", interactive=False)\n",
    "\n",
    "                doc1_output = gr.Textbox(label=\"Document 1\", interactive=False)\n",
    "                doc2_output = gr.Textbox(label=\"Document 2\", interactive=False)\n",
    "                doc3_output = gr.Textbox(label=\"Document 3\", interactive=False)\n",
    "\n",
    "        def choose_prompt(method):\n",
    "            if method == 'no search':\n",
    "                return \"\"\"\n",
    "                You are a specialized agent answering questions based on your knowledge. Only answer in English.\n",
    "                \"\"\"\n",
    "            else:\n",
    "                return \"\"\"\n",
    "                You are a specialized agent answering questions using only the provided documents. Select the most relevant documents that answer the question, and provide the answer based solely on them. If no documents answer the question, do not provide an answer. If context is given, it will be provided after the question.\n",
    "                \"\"\"\n",
    "\n",
    "        def process_query(query, method, groq_key_input, rerank, temperature, use_context):\n",
    "            top_docs = perform_rag(query, index, corpus, metadata, method=method, top_n=3, rerank=rerank)\n",
    "            \n",
    "            system_prompt = choose_prompt(method)\n",
    "            answer = perform_llm(query, use_context, groq_key_input=groq_key_input, top_docs=top_docs, system_prompt=system_prompt, temperature=temperature)\n",
    "            \n",
    "            docs_texts = [f\"Chapter {doc['chapter_number']}, Section {doc['section_number']}. {doc['text']}\" for doc in top_docs]\n",
    "            while len(docs_texts) < 3:\n",
    "                docs_texts.append(\"\")\n",
    "            return answer, docs_texts[0], docs_texts[1], docs_texts[2]\n",
    "\n",
    "        gr.Button(\"Execute Search and Get Answer\").click(\n",
    "            process_query,\n",
    "            inputs=[query_input, method_input, groq_key_input, rerank_input, temperature_input, use_context],\n",
    "            outputs=[results_output, doc1_output, doc2_output, doc3_output]\n",
    "        )\n",
    "\n",
    "    return demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e3d6add9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing BM25 Search...\n",
      "Performing Reranking...\n"
     ]
    }
   ],
   "source": [
    "interface = create_interface()\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0642fca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
